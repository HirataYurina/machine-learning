# Machine Learning

> 利用python实现机器学习算法：
>
> 支持向量机
>
> 决策树
>
> 朴素贝叶斯
>
> 集成学习：AdaBoost, Bagging, Random Forest
>
> 期望最大化算法（EM）
>
> k-nn
>
> k-means
>
> 主成分分析
>
> 奇异值分解

## Support Vector Machine

支持向量机的推演思想主要是：

* 间隔最大化
* 拉格朗日乘子法
* 拉格朗日对偶函数

支持向量机代码实现的主要思想：

* 基于SMO的支持向量机实现

**最基本的支持向量机只支持二分类任务，如果需要实现多分类任务，可以使用以下两种方法：**

以手写数字识别为例：任务中一共有10个类别，需要利用支持向量机对手写数字进行分类。

* 一对多：将1设置为正类，其余数字为负类；将2设置为正类，其余数字设置为负类；...以此类推；一共需要10个分类器，最后将预测数据依次输入10个分类器中，结果为正类则预测为该数字。如果多个分类器判定结果为正类，则使用到分类超平面的距离大小来选择预测结果。
* 一对一：一共训练10*9/2个分类器，依次为1VS2，1VS3，1VS4，...，2VS3，...。但是，一对一投票机制有个缺点，就是随着分类目标数目增多，分类器数目显著上升。
* 有一些改进的支持向量机算法，专门针对多分类。

***

## AdaBoost

集成学习通过构建并组合多个学习器来完成学习任务。

集成学习分为：

* 同质集成学习：学习器都是同一类的，里面的学习器称之为基学习器。
* 异质集成学习：学习器不是同一类的，里面的学习器称之为个体学习器。

集成学习将多个弱学习器集成为一个强学习器。

* 弱学习器：二分类问题上，精度略高于50%的学习器。

**集成学习主要思想：**

1. 在每一轮迭代中，改变数据分布，使得预测错误的样本在下一轮学习中受到更多的关注，可以使用重赋权法和重采样法。

2. 给每个学习器赋予一个权重，表现好的学习器（资深专家）权重越高（在投票过程中，对结果的影响越大）。

3. **总结为：两个指标，样本关注度和学习器影响力。**

   

## ToDO

* [x] 支持向量机
* [x] AdaBoost
* [ ] Bagging
* [ ] Random Forest
* [ ] Decision Tree
* [ ] Gibbs Sampling